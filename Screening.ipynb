{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35485b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "gauth = GoogleAuth()           \n",
    "drive = GoogleDrive(gauth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e118b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import webbrowser\n",
    "import requests\n",
    "import docx2txt\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0928a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FileUpload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbbee03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter path of resume: resumes/fadhila resume.docx\n"
     ]
    }
   ],
   "source": [
    "path= input('Enter path of resume: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c870a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resumes/fadhila resume.docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a91c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def split_string():\n",
    "    doc = docx2txt.process(path)\n",
    "    import string\n",
    "    global tesxt_list\n",
    "    res = re.sub('['+string.punctuation+']', '', doc).split()\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "267f1cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fadhila', 'Yousuf', 'Data', 'Scientist', 'LinkedIn', 'httpslinkedincominfadhilayosof', 'GitHub', 'httpsgithubcomfadhilayosof', 'Portfolio', 'httpsfadhilayosofgithubioPortfolio', '4429', 'count', 'ct', 'sterling', 'Heights', 'MI', '48310', 'Cell', 'no', '5867189379', 'fmyosofmtuedu', 'PROJECTS', 'Identifying', 'Symptoms', 'of', 'Orthopedic', 'Patients', 'as', 'Normal', 'or', 'AbnormalClassification', 'Problem', 'Skills', 'used', 'Python', 'Pandas', 'sklearn', 'Matplotlib', 'Project', 'Objective', 'Classifying', 'Biomechanical', 'Features', 'of', 'Orthopedic', 'Patients', 'based', 'on', 'provided', 'features', 'to', 'decrease', 'the', 'time', 'required', 'for', 'diagnosis', 'Quantifiable', 'result', 'We', 'could', 'classify', 'the', 'type', 'of', 'tumour', 'resulting', 'in', '85', 'accuracy', 'using', 'the', 'Kmeans', 'algorithm', 'with', 'K5', 'We', 'could', 'classify', 'the', 'same', 'result', 'with', '82', 'accuracy', 'by', 'using', 'the', 'Naive', 'Bayes', 'model', 'GithubhttpsgithubcomfadhilayosofKnnNbProject1blobmainKnnNbProjectipynb', 'Implementing', 'Deep', 'Neural', 'Network', 'With', 'Keras', 'For', 'Handwriting', 'Classification', 'and', 'Recognition', 'MNIST', 'Dataset', 'Skills', 'Used', 'Matplotlib', 'NumPy', 'Seaborn', 'Sklearn', 'Python', 'Neural', 'Networking', 'Keras', 'Tensorflow', 'Project', 'Objective', 'Implementing', 'Deep', 'Neural', 'Network', 'with', 'Keras', 'for', 'handwriting', 'classification', 'and', 'recognition', 'Quantifiable', 'Results', 'We', 'could', 'classify', 'the', 'type', 'of', 'number', 'resulting', 'in', '97', 'accuracy', 'Githubhttpsgithubcomfadhilayosofhandwrittingrecognitionproject', 'TalkingData', 'Project', 'on', 'Bagging', 'and', 'Boosting', 'Ensemble', 'Model', 'Skilled', 'Used', 'PythonPandas', 'and', 'sklearn', 'Project', 'Objective', 'The', 'classification', 'goal', 'is', 'to', 'The', 'data', 'contains', 'observations', 'of', 'about', '240', 'million', 'clicks', 'and', 'whether', 'a', 'given', 'click', 'resulted', 'in', 'a', 'download', 'or', 'not', '10', 'Quantifiable', 'Result', 'We', 'could', 'predict', 'whether', 'a', 'given', 'click', 'resulted', 'in', 'a', 'download', 'or', 'not', 'The', 'accuracy', 'of', 'the', 'XGBoostClassifier', 'is', '9487', 'Accuracy', 'of', 'the', 'Bagging', 'classifier', 'accuracy', 'is', '99', 'Used', 'the', 'XGBoostClassifier', 'BaggingClassifier', 'whether', 'a', '240', 'million', 'click', 'resulted', 'in', 'a', 'download', 'or', 'not', 'Compared', 'predictive', 'performance', 'by', 'fitting', 'an', 'XGBoostClassifier', 'BaggingClassifier', 'model', 'to', 'the', 'data', 'Selected', 'best', 'model', 'based', 'on', 'the', 'train', 'and', 'test', 'performance', 'GithubhttpsgithubcomfadhilayosofBaggingBoostingProjectblobmainBaggingBoostingProjectipynb', 'Examining', 'the', 'effect', 'of', 'environmental', 'factors', 'and', 'weather', 'on', 'Bike', 'rentals', 'Linear', 'Regression', 'Skills', 'used', 'Python', 'Pandas', 'sklearn', 'Linear', 'Regression', 'Project', 'Objective', 'Predicting', 'Bike', 'rental', 'demand', 'on', 'a', 'basis', 'of', 'weather', 'and', 'seasonal', 'factors', 'in', 'advance', 'to', 'take', 'appropriate', 'measures', 'which', 'finally', 'will', 'result', 'in', 'bike', 'utilization', 'Quantifiable', 'result', 'We', 'could', 'predict', 'the', 'rental', 'bike', 'count', 'resulting', 'in', '78', 'Accuracy', 'Used', 'Linear', 'Regression', 'to', 'predict', 'the', 'number', 'of', 'bikes', 'rented', 'in', 'the', 'city', 'of', 'Seoul', 'Githubhttpsgithubcomfadhilayosoflinearregressionproject', 'Predicting', 'Employee', 'Attrition', 'Skills', 'used', 'Python', 'Pandas', 'SKlearn', 'MatplotlibDecisionTreeRegressorLinearRegression', 'Project', 'Objective', 'Using', 'machine', 'learning', 'to', 'predict', 'employee', 'attrition', 'in', 'Python', 'We', 'use', 'linear', 'Regressionand', 'Decision', 'Tree', 'Regressor', 'as', 'classifier', 'for', 'employee', 'attrition', 'and', 'measure', 'the', 'accuracy', 'of', 'models', 'that', 'are', 'built', 'Quantifiable', 'Result', 'We', 'could', 'predict', 'Employee', 'Attrition', 'using', 'linear', 'regression', 'model', 'The', 'accuracy', 'of', 'linear', 'regression', 'is', '97', 'Encoded', 'categorical', 'variables', 'to', 'numeric', 'using', 'Sklearn', 'due', 'to', 'the', 'presence', 'of', 'many', 'string', 'columns', 'The', 'selected', 'best', 'model', 'is', 'based', 'on', 'train', 'and', 'test', 'performance', 'GithubhttpsgithubcomfadhilayosofSuicideRatesOverview1985to2016project', 'Clustering', 'of', 'San', 'Fransisco', 'Employees', 'based', 'on', 'salary', 'Unsupervised', 'Learning', 'K', 'means', 'Cluster', 'Skilled', 'Used', 'PythonPandas', 'and', 'sklearn', 'Project', 'Objective', 'The', 'classification', 'goal', 'is', 'to', 'find', 'the', 'number', 'of', 'clusters', 'for', 'the', 'data', 'Policymakers', 'to', 'understand', 'how', 'they', 'can', 'improve', 'on', 'their', 'policies', 'for', 'employee', 'benefits', 'Quantifiable', 'Result', 'We', 'could', 'predict', 'a', 'number', 'of', 'clusters', 'Used', 'the', 'clustering', 'algorithms', 'KMeans', 'and', 'Hierarchical', 'clustering', 'GithubhttpsgithubcomfadhilayosofkmeansprojectblobmainCopyofkmeansprojectipynb', 'EXPERIENCE', 'Graduate', 'Assistant', 'Department', 'of', 'Mathematics', 'and', 'Statistics', 'Michigan', 'Tech', 'University', '20152018', 'Extensive', 'experience', 'working', 'with', 'large', 'data', 'sets', 'Exceptional', 'ability', 'in', 'analyses', 'and', 'model', 'and', 'data', 'interpretation', 'Prepared', 'data', 'analysis', 'plans', 'and', 'produced', 'chartsgraphs', 'and', 'statistical', 'reports', 'Outstanding', 'problemsolving', 'skills', 'Teacher', 'Assistant', 'Department', 'of', 'Statistics', 'University', 'of', 'Tripoli', 'Libya', '20082013', '…', 'SKILLS', 'Programming', 'Languages', 'Python', 'Library', 'NumPy', 'Pandas', 'Matplotlib', 'Seaborn', 'Scikitlearn', 'NLTK', 'TensorFlow', 'Keras', 'Data', 'Science', 'Skills', 'Data', 'Visualization', 'Data', 'Cleaning', 'Exploratory', 'Data', 'Analysis', 'Probabilities', 'Statistics', 'Machine', 'Learning', 'Predictive', 'Modeling', 'Model', 'Optimization', 'Deep', 'Learning', 'NLP', 'Model', 'Deployment', 'Computer', 'Vision', 'Database', 'MySQL', 'SQL', 'server', 'Other', 'Skills', 'GitGitHub', 'Auto', 'CAD', 'Soft', 'Skills', 'Problem', 'Solving', 'Collaboration', 'Critical', 'Thinking', 'CERTIFICATION', 'Machine', 'Learning', 'AZ™', 'HandsOn', 'Python', 'R', 'in', 'Data', 'Science', '2020', 'The', 'Data', 'Visualization', 'Excel', 'Tableau', 'Python', 'R', 'Certificate', '2020', 'The', 'Complete', 'SQL', 'Bootcamp', '2021', 'EDUCATION', 'Bootcamp', 'Data', 'Science', 'TECH', 'IS', 'Santa', 'Clara', 'October', '2021January', '2022', 'Graduated', 'as', 'a', 'Data', 'Scientist', 'in', 'an', 'accelerated', 'program', 'with', 'an', 'immersive', 'handson', 'project', 'work', 'experience', 'in', 'Python', 'ML', 'AI', 'NLP', 'Analysis', 'Data', 'Visualization', 'Probabilities', 'Statistics', 'Learning', 'Intelligence', 'etc', 'Michigan', 'Tech', 'University', 'Houghton', 'MI', 'MS', 'in', 'Statistics', '2018', 'Tripoli', 'University', 'Libya', 'MS', 'in', 'Statistics', '2008', 'AlJabal', 'Al', 'Gharbi', 'University', 'Gharyan', 'Libya', 'BA', 'in', 'Mathematics', '2001']\n"
     ]
    }
   ],
   "source": [
    "text_list=split_string()\n",
    "print(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b919396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Science\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(text_list)):\n",
    "  \n",
    "  if text_list[i]==('Pandas' or 'Neural' or 'Sklearn' or 'Matplotlib' or 'Tensorflow'):\n",
    "    field='Data Science'\n",
    "  if text_list[i]==\"Django\":\n",
    "    field='Web Developer'\n",
    "print(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4211c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student():\n",
    "    if text_list[2]==('Data' or 'Web'):\n",
    "         Student_name=text_list[0]+' '+text_list[1]\n",
    "    if text_list[2]!=('Data' or 'Web'):\n",
    "        Student_name=text_list[0]+' '+text_list[1]+' '+text_list[2]\n",
    "    return Student_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "352f7557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fadhila Yousuf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdc935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46a2886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866/\n",
      "Running on public URL: https://10469.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"https://10469.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc0513dec70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<fastapi.applications.FastAPI at 0x7fc04e313c70>,\n",
       " 'http://127.0.0.1:7866/',\n",
       " 'https://10469.gradio.app')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def class_resume(path):\n",
    "    def split_string():\n",
    "        doc = docx2txt.process(path)\n",
    "        import string\n",
    "        global tesxt_list\n",
    "        res = re.sub('['+string.punctuation+']', '', doc).split()\n",
    "        return res\n",
    "    text_list=split_string()\n",
    "    def student():\n",
    "        if text_list[2]==('Data' or 'Web'):\n",
    "             Student_name=text_list[0]+' '+text_list[1]\n",
    "        if text_list[2]!=('Data' or 'Web'):\n",
    "            Student_name=text_list[0]+' '+text_list[1]+' '+text_list[2]\n",
    "        return Student_name\n",
    "    for i in range(len(text_list)):\n",
    "        \n",
    "      if text_list[i]==('Pandas' or 'Neural' or 'Sklearn' or 'Matplotlib' or 'Tensorflow'):\n",
    "        field='Data Science'\n",
    "        \n",
    "\n",
    "      if text_list[i]==\"Django\":\n",
    "        field='Web Developer'\n",
    "    \n",
    "    #print(field)\n",
    "    return field,Student_Name\n",
    "\n",
    "iface = gr.Interface(fn=class_resume, inputs=\"text\", outputs=\"text\",title=\"Resume Classification\",)\n",
    "iface.launch(share= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb38cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detection(frame):\n",
    "    height, width, channel = frame.shape\n",
    "  # Convert frame BGR to RGB colorspace\n",
    "    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "  # Detect results from the frame\n",
    "    result = face_detection.process(imgRGB)\n",
    "  # Extract data from result\n",
    "    for count, detection in enumerate(result.detections):\n",
    "            \n",
    "          # print(detection)\n",
    "     # Extract bounding box information\n",
    "        box = detection.location_data.relative_bounding_box\n",
    "        x, y, w, h = int(box.xmin*width), int(box.ymin * height),int(box.width*width), int(box.height*height)\n",
    "    # If detection is not available then pass\n",
    "    return x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdf20836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.8.9.1-cp38-cp38-macosx_10_15_x86_64.whl (33.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.4/33.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.5.5.64-cp36-abi3-macosx_10_15_x86_64.whl (55.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/musubimanagement/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (1.20.1)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in /Users/musubimanagement/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (3.19.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/musubimanagement/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: absl-py in /Users/musubimanagement/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in /Users/musubimanagement/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (3.3.4)\n",
      "Requirement already satisfied: six in /Users/musubimanagement/opt/anaconda3/lib/python3.8/site-packages (from absl-py->mediapipe) (1.12.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/musubimanagement/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/musubimanagement/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/musubimanagement/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/musubimanagement/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/musubimanagement/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Installing collected packages: opencv-contrib-python, mediapipe\n",
      "Successfully installed mediapipe-0.8.9.1 opencv-contrib-python-4.5.5.64\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c520ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import mediapipe as mp\n",
    "face_detection = mp.solutions.face_detection.FaceDetection()\n",
    "from tensorflow.keras.models import load_model\n",
    "# load the model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "800cd80c",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-237528684a90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcrop_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcrop_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mcrop_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4-dev) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = ['mask', 'no_mask']\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _,frame=cap.read()\n",
    "    img=frame.copy()\n",
    "    x,y,w,h=get_detection(frame)\n",
    "    crop_img=img[y:y+h,x:x+w]\n",
    "    crop_img = cv2.resize(crop_img, (100, 100))\n",
    "    crop_img = np.expand_dims(crop_img, axis=0)\n",
    "    prediction = model.predict(crop_img)\n",
    "    index = np.argmax(prediction)\n",
    "    res = CATEGORIES[index-1]\n",
    "    if index == 0:\n",
    "        color = (0, 0, 255)\n",
    "    else:\n",
    "        color = (0, 255, 0)\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "    cv2.putText(frame, res, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX,0.8, color, 2, cv2.LINE_AA)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78cf845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
